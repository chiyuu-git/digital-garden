---
{"aliases":[],"tags":[],"review-dates":[],"dg-publish":true,"date-created":"2022-09-03-Sat, 10:07:55 pm","date-modified":"2023-04-29-Sat, 8:10:47 pm","permalink":"/programming/front-end/framework/engineering/seo/","dgPassFrontmatter":true}
---


# UTM 参数

[超链接中 utm\_source, utm\_medium 等参数的含义是什么？ - 知乎](https://www.zhihu.com/question/48724061/answer/122730629)

# 什么是 SEO

## 概述

搜索引擎优化（Search Engine Optimization，简称 SEO）是一种利用搜索引擎的搜索规则来提高目的网站在有关搜索引擎内的排名的方式。

研究发现，搜索引擎的用户往往只会留意搜索结果最前面的几个条目，所以不少网站都希望通过各种形式来影响搜索引擎的排序。当中尤以各种依靠广告维生的网站为甚。SEO 是指通过采用易于搜索引擎索引的合理手段，使网站各项基本要素适合搜索引擎检索原则并且对用户更友好（Search Engine Friendly），从而更容易被搜索引擎收录及优先排序。使你的网站在百度和 Google 的排名提高，让搜索引擎给你带来客户。

深刻理解是：通过 SEO 这样一套基于搜索引擎的营销思路，为网站提供生态式的自我营销解决方案，让网站在行业内占据领先地位，从而获得品牌收益。

在国外，SEO 开展较早，那些专门从事 SEO 的技术人员被 Google 称之为“Search Engine Optimizers”，简称 SEOers。由于 Google 是世界最大搜索引擎提供商，所以 Google 也成为了全世界 SEOers 的主要研究对像，为此 Google 官方网站专门有一页介绍 SEO，并表明 Google 对 SEO 的态度

### 搜索引擎与蜘蛛

搜索引擎根据一定的策略、运用特定的计算机程序从互联网上搜集信息，在对信息进行组织和处理后，为用户提供检索服务，将用户检索相关的信息展示给用户的系统。

学习搜索引擎优化 SEO，必须先了解什么是搜索引擎以及**搜索引擎原理**。搜索引擎包括全文索引、目录索引、元搜索引擎、垂直搜索引擎、集合式搜索引擎、门户搜索引擎与免费链接列表等。

在搜索引擎网站的后台会有一个非常庞大的数据库，里面存储了海量的关键词，而每个关键词又对应着很多网址，这些网址是被称之为“搜索引擎蜘蛛”或“网络爬虫”程序从茫茫的互联网上一点一点下载收集而来的。随着各种各样网站的出现，这些勤劳的“蜘蛛”每天在互联网上爬行，从一个链接到另一个链接，下载其中的内容，进行分析提炼，找到其中的关键词，如果“蜘蛛”认为关键词在数据库中没有而对用户是有用的便存入后台的数据库中。反之，如果“蜘蛛”认为是垃圾信息或重复信息，就舍弃不要，继续爬行，寻找最新的、有用的信息保存起来提供用户搜索。当用户搜索时，就能检索出与关键字相关的网址显示给访客。

一个关键词对用多个网址，因此就出现了排序的问题，相应的当与关键词最吻合的网址就会排在前面了。在“蜘蛛”抓取网页内容，提炼关键词的这个过程中，就存在一个问题：“蜘蛛”能否看懂。如果网站内容是 flash 和 js 等，那么它是看不懂的，会犯迷糊，即使关键字再贴切也没用。相应的，如果网站内容可以被搜索引擎能识别，那么搜索引擎就会提高该网站的权重，增加对该网站的友好度。这样一个过程我们称之为 SEO。

## SEO 主体框架

- **SEO 流量=整体搜索量 X 整体收录 X 整体排名 X 整体点击率**

### 整体搜索量

整体搜索量，即一段周期内行业的总搜索流量。比如 A 行业，日均总搜索流量为 1000 万，那么该行业的日均整体搜索量即为 1000 万。

很多行业都有淡旺季之分，因此有时 SEO 流量提升或者下降了，并不一定就真是 SEO 操作成功或者失败了，有可能是行业的整体搜索趋势影响的。

整体搜索量直接决定了行业内每家网站所能获得的流量空间有多大。比如 A 行业日均 1000 万搜索量，B 行业日均 500 万搜索量，一般说来 A 行业网站的 SEO 流量空间要比 B 行业大，即 SEO 流量天花板前者要比后者高

### **整体收录**

整体收录指的是网站在搜索引擎中被收录的页面数量。比如 A 网站页面总量为 10 万，百度收录了 8 万，整体收录就是 8 万。

整体收录直接决定了网站有多少页面可在搜索引擎中获取流量。比如旅游行业 B、C 网站整体收录分别为 1000 万与 500 万个页面，这就说明前者有 1000 万个页面可以获取搜索流量，而后者只有 500 万，在两站 SEO 水平差距不大的情况下，很显然前者能获取更多的 SEO 流量。

衡量一个网站收录好坏的指标为收录率，即，收录率=被收录的页面数量/网站页面总量。

前面说的 A 网站，收录率即为 80%。一般来说，收录率的好坏基本遵循以下规律：低于 60% 为差，60%-80% 为良好，80% 以上为优秀。是不是和上学时的成绩优良评价标准类似，只是这里几乎无 100% 收录的，除非网站是单页面站点。

以上是笼统的来介绍收录，真正实际操作中会精确到具体页面类型的收录率。

### **整体排名**

- 整体排名指的是被收录的页面在搜索结果中的整体排名情况，这里一般指的是排在第一页。因为从第二页开始，就几乎没用户点击了。
- 比如，搜索 100 个词，A、B 网站排在第一页的页面数量分别为 80 与 40，显然 A 站比 B 站的排名能力更强，也更容易获取 SEO 流量。
- 整体排名体现了一个网站的排名竞争力，在排除收录影响的因素下，可以认为一个网站的整体排名越强，其 SEO 优化水平也越高，也更值得我们去学习。

### **整体点击率**

- 整体点击率指的是页面被点击的次数/页面被展示的次数。
- 比如 A 网站一天在百度搜索中被展示了 100 次，点击为 10 次，那么整体点击率即为 10%。
- 由于在百度搜索结果中最被用户关注的是网页标题和描述，而往往较能满足用户搜索需求且有吸引力的标题或者描述，越能获取更多的用户点击。
- 从这一层面来说，整体点击率往往体现了网页标题和描述是否能满足用户需求，并且具有创意性。

## SEO 分类

### 白帽 SEO

+ SEO 白帽是一种公正的手法，是使用符 合主流搜索引擎发行方针规定的 SEO 优化方法。
+ 一直被业内认为是最佳的 SEO 手法，它是在避免一切风险也避免了与搜索引擎发行方针发生任何的冲突，它也是 SEOer 从业者的最高职业道德标准。
+ 因为搜索引擎是以文本为中心，许多有助于网页亲和力的同样手段同样便利于搜索引擎优化。
+ 这些方法包括优化图形内容、 ALT 属性和增加文本说明。甚至 Flash 动画可于设计该页时包括替代性内容，这本来用来给访客无法阅读 Flash 的环境用的，来帮助优化。

### 黑帽 SEO

+ 笼统的说，所有使用作弊手段或可疑手段的，都可以称为黑帽 SEO。
+ 比如说垃圾链接，隐藏网页，刷 IP 流量，桥页，关键词堆砌等等。
+ SEO 黑帽是一种不为 搜索引擎所支持的违规行为，因为黑帽 SEO 挑战了行业道德底线，因此为被广大白帽 SEO 而所不齿。
+ 垃圾索引（Spamdexing）意指通过欺骗技术和滥 用搜索算法来推销毫不相关、主要以商业为着眼的网页。
+ 许多搜索引擎管理员认为任何搜索引擎优化的形式，其目的用来改进站点的页排名者，都是垃圾索引。然而，随时间流逝，业界内公众舆论发展出哪些是哪些不是可接受的、促进某站的搜索引擎排名与流量结果的手段。
+ 常用技术：<https://lusongsong.com/info/post/11783.html>

## 灰色 SEO 代表：快排

快速排名点击算法的核心步骤和核心算法过程。按照正常的点击来说，大致会有四个流程，下面我给大家详细的一一说明每一步流程的操作和注意点。

**第一、流量入口**

什么是流量入口呢?大致会有下面几点，比如浏览器 (360、搜狗等) 的选择、导航网址 (好 123、2345 等) 的进入、PC 端或者移动端的访问。这也是快速排名的第一步，有人会问为何要有流量入口这个说法呢，大家想一下，真实的用户通过关键词进入网站肯定是多个渠道多个入口进来的，所以很多人在做快速排名的时候用同一款浏览器同一个电脑访问，哪怕你切换了 IP 你照样逃离不了搜索引擎的追逐。因为在流量入口这个过程里面，搜索引擎一般会有两种方式来判断你的数据真实性。如果大家用过 [百度](https://lusongsong.com/tags/baidu.html) 统计的都知道，每一个用户的访问来路里面会有一个访客标识码，所以就算你切换了 IP，你的访客标识码依然不会改变，这也是为何很多人切换了浏览器点击效果依然不佳的原因。当然要想解决这个问题也很简单，首先我们要去了解一下访客标识码是怎么来的，由于国内的主流浏览器的内核多数都是 IE 内核，比如 360 浏览器、搜狗浏览器等等。所以你切换了浏览器访客标识码会依然一致，其实访客标识码的生成是通过 cookies 来抓取的。所以要想改变你的访客标识码那么每点击一次清除你的浏览器 cookies 即可。当然，除了访客标识码，[搜索引擎还会有一种验证你点击真实性的方案](https://lusongsong.com/reed/831.html)，也就是下面我要和大家谈的第二点步骤 - 点击轨迹。

**第二、点击轨迹**

那么什么是点击轨迹呢?我们可以这么理解，点击轨迹是你从搜索一个关键词开始到进入到你所需要优化的网站里面，而这一段过程就成为搜索点击轨迹。下面我给大家举一个例子，比如我们通过 IE 浏览器的好 123 导航网址进入百度搜索卢松松这个关键词，那么浏览器的最顶部框里面会有对应的一个轨迹参数，比如刚刚我搜索卢松松的轨迹如下：

<https://www.baidu.com/s?word=卢松松&;tn=sitehao123&ie=utf-8&ssl_sample=ssl_1>

我们可以从上面的数据看出一些东西出来，比如 word=卢松松，说明用户是搜索关键词卢松松。&该符号在代码里面的解释是并且的意思，tn=sitehao123 意思就是说该关键词是通过好 123 导航进入的，ie=utf-8 说明用户是通过 ie 浏览器或者 ie 内核并且编码状态时 utf=8 形式进入百度搜索的，至于最后面一段应该是属于加密的数据 (因为这句我也不是非常清楚)。当我们把这些参数数据解答完毕以后我们在回头看一下，搜索引擎竟然会记录出这些数据，所以你如果像把点击变得更加的真实，那么这些你一定要做的非常极致，否则，你的排名不仅不会上升甚至会下降。当然点击轨迹不会这么简单，这只是点击轨迹的第一步。搜索引擎不仅仅会记录你的搜索轨迹，还可以记录更加深层次的东西。比如我们搜索卢松松以后再去搜索卢松松博客，搜索轨迹参数如下：

<https://www.baidu.com/s?ie=utf-8&;f=8&rsv_bp=1&tn=sitehao123&wd=卢松松博客&oq=卢松松&rsv_pq=d05e50f10001c409&rsv_t=7413WhSrzX6eNi33JwZ9EbpxBs%2FvSWKv9lcK7Zmnn9nilnyp4u9Q9l5p%2F9yn3UkGMg&rsv_enter=1&rsv_sug3=2&rsv_sug1=2&rsv_sug2=0&inputT=639&rsv_sug4=1357>

不知道大家有没有看懂，其实**搜索引擎不仅仅会记录你一次的搜索词，它还会记录你上一次的检索结果**。所以你可以想想一下，真正的用户在向搜索引擎请求一个结果的时候往往没有找到相关的结果条件，那么会继续搜索和上一次检索词相关的关键词出来再去进行搜索。所以很多人做点击排名在这一点上面做的并不是很理想，因为他压根不知道搜索引擎的点击算法是什么，仅仅只知道单纯的点击而已。当然说到这里，肯定很多人会想那如果我第一个请求就找到了用户所要的结果呢?那么继续搜索的话不是相关词怎么办呢?所以搜索引擎还会有一套解决真实用户的机制，那就是跳出率。提到这里，我要给大家扫盲一下，很多人认为什么百度统计、站长统计的跳出率，如果过高对优化不好。大家想一下，除了百度统计自家以外，如果采用其他统计工具的网站，搜索引擎怎么计算跳出率呢?真正的跳出率是当用户搜索一个关键词进入到该网站，然后再返回搜索页面点击进入另外一个网站，而第一个网站的进入时间和第二个网站的进入时间这一段的时间值则是搜索引擎计算的网站跳出率。比如一个用户找到了自己想要的信息，那么多数会关闭搜索页面，或者不再去进行其他词的二次搜索。也正是这样，我们回到前面的话题，当我们搜索一个词就找到结果了以后在去搜索和现有关键词不相关的关键词的时候会有一个时间差。**而这个时间差正好是搜索引擎用来判断你是否作弊的尺度**。正常用户如果真正的找到自己想要的结果，就算要进行第二次的搜索，那么他们也会把当前的网站内容看完，即时是一分钟，那么在这一分钟里面这个网站的跳出率就是一分钟的时间，过了这一分钟你再去搜索其他不相关的内容搜索引擎就会第二次进行其他词的判断。所以很多人尤其是互点的，帮一个人点完了一个关键词，不到 10 秒，马上又去帮助另外一个人点击，造成了关键词的跳出率极高，真实性极差的一个结果，所以你的排名只会停留在原来甚至下降的位置。

**第三、点击次数**

当我们把点击排名最重要的两点说完以后，我们应该来思考下一个关键词每天点击量多少才是最合适呢?正常的情况比如一个 100 指数的关键词在第二页。那么我们的日点击量可以在 10% 到 15% 左右，当然第一天最好是 5%，然后第二天开始逐渐增加，因为真实的网站就算你的用户体验好，点击量也不是一气呵成的，都是通过数据积累而逐渐上升。

**第四、时间段**

这是看起来最不重要的一个步骤，但是也是非常重要的步骤，比如关键词的每日点击是 20 次，那么这 20 次尽可能的在点击时间段隔开起来，可以选择集中白天不同时段点击，晚上削减点击。

当我们上面整个的 4 个点击阶段点击完成以后，一整套的点击算法流程就基本上完成了，这也是现在很多做快速排名的常用的手段和方式。当然这仅仅是其中一种而已，下面我给大家讲解一下一些专门接单的快排团队他们是如何操作快排的。

很多人做过快排的会知道，请人快排 [优化关键词](https://lusongsong.com/reed/317.html)，不会像上面单纯的点击一样会产生流量，可能你会发现你的排名迅速提升，但是却没有任何的点击流量，统计工具也抓取不到数据。最重要的是效果还很稳定并且不仅仅是针对前三页的关键词优化，甚至前 100 名的关键词都可以优化上来，那么他们是通过何种快排技巧做到的呢?下面就给大家讲解下当今快排的另外一种技巧，也就是所谓的发包。

何为发包呢?简单来说发包就是利用搜索引擎的漏洞发送数据请求然后传输相对应的数据，当然这组数据也可以算是点击数据，只不过这组数据是通过数据发包形式传送，比如研发这类软件的会提前设置好对应的浏览器参数、相关搜索词参数等等数据参数，这样可以**直接提交给搜索引擎以达到不用真实人为点击**就可以对网站增加点击量的目的。之所以这种数据发包效果要好很多，就是因为相对于人为的模拟点击它具有稳定性的特点。因为人为的虚拟点击不可能做到每个点击都是如此的完美。但是利用发包软件却可以做到用户体验的最大化，也这是为何现在很多请人做快排却没有产生流量点击排名如此稳定的原因。

当你看完这篇文章，我相信你应该大致的详细了解了点击算法的基本流程和市面上这一类快速排名方式了。

## SEO 演化

SEO 直到现在为止仍然是网络营销领域非常重要的营

销手段之一，不管你的企业是做什么的，或者是个人创业，只

要学会了 SEO 之后，就可以把关键词排在搜索引擎前面，获

得海量的精准目标客户。

在 SEO 领域，算法一直都是站长们头疼的事情，而且非

常多的站长心里都很浮躁，每天都想去研究搜索引擎的算

法，找漏洞做快速排名，做黑帽钻搜索的空子。

这样往往搜索引擎算法一更新，排名就没有了，资深的

站长一定有这样的体会。想要真正做好 SEO，最主要的还是

要搞清楚，搜索引擎的核心算法，明白了这一点，不管今后的

算法怎么改变，都可能推算出来。

搜索引擎的算法演变过程，主要分四个阶段。

分类目录；

文本技术；

链接技术；

行为分析。

分类目录

这是最早时期的搜索引擎雏形，主要是在 2001 年以前，

这个阶段，上网都是在网吧，当时人们主要是通过目录查找

的方式来上网，用的主要搜索工具是 google 和雅虎，百度在

那时候并没有现在这么热，当时雅虎在国内很出名，而雅虎

的分类目录也是上网时用的最多的。这阶段只要网站在提交

的时候，技巧性的把网站的标题写好，就可以获得非常好的

排名。

文本技术

这个时期主要是 2001~2004 年，这个阶段的搜索引擎虽

然有链接分析的技术，但是主要算法还是以文本为主，当时

的 SEO 也非常的简单。那时搜索引擎主要是根据页面关键

词的密度来排名的，只要网站页面中的关键词密度足够高，

排名就会非常好。

不过这个也导致了非常多的垃圾站群网站的出现，使得

搜索引擎不得不升级算法，清理垃圾网站。

链接技术

相信链接分析技术网站是最多的，这时期主要是从

2004~2009 年，这个阶段，在站长圈流传一句话“内容为王，链

接为皇”，那时候搜索引擎主最要的算法就是通过反向链接

来计算网站的排名，反向链接越多，排名就越好。

于是后来又导致了非常多的垃圾网站出来，各种垃圾链

接通过买链接、挂黑链等获得的排名，最后搜索引擎再次升

级，又一大批网站被清理。但是关于反向链接直到现在依然

在使用。

行为分析

这个阶段主要的算法有两个：内容和用户行为。早在

2006 年的时候，发生了一件事情，当初 CN 域名一块钱就可

以注册，导致非常多的垃圾站群出来，导致百度的硬盘不够

用，让百度苦不堪言。最后只能是人工删除了垃圾内容，同时

升级了内容原创分析技术。

2009 年以后社交网站和社交应用火了之后，各种新的应

用层出不穷，各大搜索引擎的算法也变得越来越智能了，并

且结合的大数据。融入了社会化网络分析的元素。

不过，搜索引擎算法改变的核心原则永远不变，那就是：

1、防止垃圾网站的作弊手段；

2、提升用户体验的技术分析。

所以，不管搜索引擎的算法如何改变，只需要站到用户

的角度，了解用户的需求，就可以推出最新的算法。

# 国内 SEO 现状

## SEO 流量分布现状

### **SEO 流量变迁**

- 这个相信大家都深有体会了，随着智能手机的发展，APP 的兴起，流量越来越多的从搜索引擎转向垂直 APP 应用，这方面网上也有大量的文章和数据进行说明，这里就不再赘述了。
- 不过，有意思的一点是，随着一些垂直内容平台与 APP 的壮大，其自身也越来越具备搜索引擎的特质，比如知乎、微信等，相信不少朋友查找问题时也曾在这两个平台搜索过。
- 虽然 SEO 流量被各类平台瓜分了很多，但 SEO 依然是网站高价值流量的来源渠道之一，是仅次于直接访问的高质量流量。
- 同时，搜索引擎中依旧有大量的搜索需求没有被满足，如何找到这块需求，并且生成相应的内容满足需求，这也是一个非常不错的项目方向，最佳案例当然是亦大的《Google 关键词挖掘细分市场实战案例》了，哈哈！

### **SEO 流量分布现状**

- 这部分包含两个方面，一是 PC 与移动两个平台流量分布状况，二是国内各搜索引擎市场份额。
- 平台分布，根据个人的观察并与同行交流，目前 PC 与移动的 SEO 流量比例基本为 3:7~4:6，个别行业 2:8 的也有。
- 可以看到移动端流量占大头，因此做好移动站的 SEO 要比做好 PC 站有价值的多，并且竞争程度也远比 PC 端小。

![1559697741330](/img/user/programming/front-end/framework/engineering/seo/1559697741330.png)

![1559697985363](/img/user/programming/front-end/framework/engineering/seo/1559697985363.png)

## 搜索引擎优化现状

+ 除了 toB 领域，其它领域对 SEO 基本不重视了;
+ 现在做 SEO，快排等灰色技术应用基本成了标配，虽然有公司宣称不做这些;
+ 用搜索引擎进行品牌宣传成为白帽 SEO 的主流，给网站引流还得靠快排等手段;
+ 熊掌号以流量加持的优势在 2018 年火了一把，让大家热情高涨，却在年终时猝死;
+ 快排服务行业开始形成知名品牌。
+ [百度](https://lusongsong.com/tags/baidu.html) 小程序会继续以流量加持的优势被关注，企业去网站去域名越来越多;
+ [快排技术会继续影响搜索引擎排名公正性](https://lusongsong.com/reed/1606.html)，甚至会主宰高利润行业的排名;
+ 具有深度学习能力的 AI 机器人写文章越来越多，质量越来越高;
+ 基本不会再诞生以 SEO 为主要引流方式的大型行业网站;
+ 会有 SEO 服务企业被法律制裁，原因可能是快排或者删帖;
+ 虽然说百度这几年出台了不少的算法来打击各种作弊，确实，一些常见的 SEO 作弊方式得到了抵制，比如说买卖链接，堆积关键词，使用 iframe 来嵌套内容等，甚至百度还开始对网站标题进行语意识别，惩罚那些夸大事实或者无中生有的网页标题。百度确实做了许多工作。

  但是排名作弊这个事情，做的人收益非常大，抓的人收益很小，所以研究作弊的人会越来越多，会购买上千服务器，数以万计的 IP 来作弊，甚至将在搜索引擎内部的工程师挖出来参与作弊。

  而对于搜索引擎来说，反作弊远没有卖更多产品出去优先级高，总是跟不上快排作弊的步伐。

  智能手机的普及，让个人的需求会优先在手机上进行满足，而那些无明确目标的娱乐内容在那些信息流推荐的 APP 会体验更好，比如头条、抖音、快手等，大家使用电脑搜索的次数日趋变少，再加上搜索引擎越来越多的将排名优先给自己的频道，所以网站对于企业来说，越来像鸡肋，大量的内容提供者将视线转向各种自媒体平台，这进一步降低了搜索引擎的作用。

  熊掌号与小程序是百度先后推广的两款产品，它解决了网站给百度带来的多种不确定性：网站打开速度慢或不安全，或者不适应手机或者广告太多，这些都会影响搜索体验。

  所以它们都有合理性，只是搜索 APP 并非是个高频的产品，基于一个低频的 APP 开展粉丝互动是否真正形成粘性?如果不看粉丝功能，[站长其实选择网站还是熊掌号还是小程序](https://lusongsong.com/info/post/61.html)，主要基于谁有排名优先权。

  **软文写作，为了排名流量或者获得推荐流量，同时也要有转发或者销售转化的功效。**但至少对于前者，机器人写作的文章，或者使用翻译软件、语音识别软件生成的文章能够满足大部分需求。

  搜索引擎算法、智能内容生成算法在博弈，落后的就会被欺负，现在看来搜索引擎算法有些停滞，这让其它的算法越来越有利可图，越来越蓬勃发展。

  预计到明年，AI 写作的文章，就能够通过百度的排名算法，以及像头条的内容推荐算法。

  中国的 SEO 公司最开始是完全照搬国外的 SEO 服务公司算法，但随着国情不同搜索引擎不同，慢慢走两条不同的路，我们国内的 SEO 大会基本上不再邀请白人来讲了。

  现在中国的 SEO 公司要么是公开地开展灰色 SEO 服务，要么是暗地里开展灰色 SEO 服务，要么就倒闭了。高大上的 PPT 能够讲清楚为什么要做 SEO，但真正做好 SEO，快排却是必不可少。

  刑天一直以来在宣传白帽优化，毕竟我也是百度的特聘讲师，也知道将灰帽技术应用于客户网站对于网站是有伤害的，所以对于快排一直在排斥，于是我便不能在企业网站优化上再有什么机会，最终我选择的是给企业做 SMO(站外发布的内容进行排名优化) 以及做品牌的推手服务，也是不得已的选择。

## 熊掌号

据网友发帖爆料熊掌号 ID 页也发生了重大改变，当小编再次进入熊掌号 ID 首页一栏，竟直接跳转到了直指百家号和小程序这个页面，看样子熊掌号真没戏了!

主页熊掌号 ID 当前已重点显示**“小程序平台和百家号平台”**，小程序平台 (图文) 排第一位，不愧当之今年风口，小程序要火熊掌号全面助力，[百度](https://lusongsong.com/tags/baidu.html) 搜索流量也给导到百家号平台里了。而度娘熊掌号 ID 如今也明摆着告诉你我关心的是啥，其百度的 (智能) 小程序更像是一步大棋 (但千万也不要被耍了)。

![çæå·å½»åºåäºï¼å¥å£å·²å¯¼åç¾å®¶å·åå°ç¨åº ç½ç« çæå· ç¾åº¦ å¾®æ°é» ç¬¬2å¼ ](https://images.lusongsong.com/zb_users/upload/2018/10/201810199387_656.jpg)

还记得上面这张图么?此前 [百度宣称移动端搜索已分发50%的流量给熊掌号资源](https://lusongsong.com/blog/post/10907.html)，目前熊掌号的解决方案貌似只剩下“百家号和小程序”了，商家号和网站基本已淡化了...

而百家号和小程序却是在给自己打壁垒，站长你也别多想了，洗洗睡吧。

## 百家号和小程序

细心的网友无意间再次发现 [百度](https://lusongsong.com/tags/baidu.html) 搜索相关最新信息 (关键词)，基本百家号文章全给“霸屏”百度了!熊掌号避而不谈，改转稳定的百家号分发流量啦。难道百度要转型做站内搜索!

如下，网友搜索时下最新热点关键词，搜索结果百家号文章首当其冲;

百度现在更像个门户，搜什么都是百家号的文章，比如最新相关信息，就全是百家号。除了最新信息都是百家号之外，有时下面的结果还有一两个是百家号。

聪明点的，搜东西都标题 + 网站名，不然老跳出百家号搬运文咋办!对比回归是个神话的谷歌，强化于搜索引擎对内容抓取及判断能力，度娘还停留让站长每日手动提交链接抓取，站长天天发百家号。

从百度系自己产品的布局看看，谁还重点管你 SEO，所有的数据都抓在自己手里，但将来的 SEO 也并完全没有，百度还需要，需要能产生优质内容的 SEO，百度现在应该在搞内容生态 (内容不仅仅单纯依靠各位站长)。

**结尾留个重磅：**百度这么做的目的其实有一个 (未来 3 到 5 年大方向) 欢迎探讨。

中小型网站依靠 SEO 提高流量的时代已经过去了

### 网站降权

+ [百度](https://lusongsong.com/tags/baidu.html) 在 2019 年貌似没出现什么算法，但是在 2 月份刚过不久被站长吐槽网站被大规模的降权，此次波动造成的影响并非一般，不少超级大站一夜回到解放前，流量下滑的厉害。
+ 百度算法和调整有时基本让人摸不着头脑，但去年 11 月份至今官方也还公布说有新的算法更新，爱捣腾的网友在被网站三番五次降权，反复的情况下也有打算放弃的念头，基本上做上去无望了。
+ 一种直接触犯了百度算法，之前公布百度算法清风算法期 3.0，2.0 期间如果收到影响还有的说，更多得反馈百度告知什么算法都没中，网站质量也可以，流量问题请自查。这种还得真研究研究了。降权其一大部分还是选择持续更新，坐等恢复迹象，多更新原创内容，其他貌似没有特别好的办法。

### 智能小程序

+ 号称 80% 搜索流量将全部分发给优质熊掌号似乎已成一纸空文了，熊掌号在智能小程序的呼声、比拼中渐渐衰落无声，[百度](https://lusongsong.com/tags/baidu.html) 搜索的流量被导向了新家园“百度智能小程序”，**消息称百度正在加速开放更多搜索流量给智能小程序开发者。**
+ 今日，从开发者嘴里透露得知，百度搜索正全面接入智能小程序，包括给予智能小程序权重的提升，开放更多流量。大致概括一句话来说：**对于同质量内容，智能小程序会在搜索会获得更高的权重，优先排名展示，并且获取更多流量。**
+ 而之所以这么有底气，据悉还有相关数据支撑，如图，智能小程序已深入 23 大行业，覆盖 262 个细分领域，月活超 1.5 亿。
+ 现在，百度搜索说要全面接入智能小程序，估计是想往小程序里导流的吧，智能小程序获得搜索强流量支持，站长是不是大概率也得往小程序上靠的呢?在流量稀缺的环境下，小程序被捧得越来越火，百家号的处境又会如何？不好说。

### 小程序资源数据统计功能

+ [百度](https://lusongsong.com/tags/baidu.html) 的智能小程序正式上线了资源收录量和点击展现量数据统计这一功能，而接入小程序的管理员或者开发者，可以通过这些数据更进一步评估小程序的流量效果情况。比公众号更强大的估计也就是小程序的数据分析功能了。

  按官方的说法，3 月 22 日搜索资源平台正式上线打通了后台小程序“资源收录”“点展数据”统计情况。

  最直观的指标莫过于资源收录情况了，如图 1 新增“收录统计”，可以在后台收录统计一栏查看小程序收录资源量，

  ![ç¾åº¦æºè½å°ç¨åºèµæºæ°æ®ç»è®¡ä¸çº¿ æ°æ®åæ ç½ç« ç¾åº¦ å¾®æ°é» ç¬¬1å¼ ](https://images.lusongsong.com/zb_users/upload/2019/03/201903238250_516.jpg)

另外，如图 2 还上线了可查看“内容点展数据”，即点击量和展现量的趋势变化、数据分析对比情况图。

目前，小程序提供的数据纬度主要这两大块，再者，未关联接入小程序的站点百度给出了“[小程序关联站点指南](https://ziyuan.baidu.com/college/articleinfo?id=2769)”点击可查看。

# 前端 SEO 规范

+ 前端是构建网站中很重要的一个环节，前端的工作主要是负责页面的 HTML+CSS+JS，优化好这几个方面会为 SEO 工作打好一个坚实的基础。通过网站的结构布局设计和网页代码优化，使前端页面既能让浏览器用户能够看懂（提升用户体验），也能让“蜘蛛”看懂（提高搜索引擎友好度）。

## 搜索引擎优化基础

### Title

- \<title>标题：只强调重点即可，尽量把重要的关键词放在前面，关键词不要重复出现，尽量做到每个页面的\<title>标题中不要设置相同的内容。

### Meta

- \<meta keywords>标签：关键词，列举出几个页面的重要关键字即可，切记过分堆砌。
- \<meta description>标签：网页描述，需要高度概括网页内容，切记不能太长，过分堆砌关键词，每个页面也要有所不同。

### 关键词类型

关键词的分类有很多种，按照不同分类方法，会得到不同

类型的关键词。

分类方法：

热度分类：热门关键词、一般关键词、冷门关键词；

长短分类：短尾关键词、长尾关键词；

主副分类：主要关键词、辅助关键词；

其他分类：泛关键词、别名关键词、时间关键词、错别关键

词、问答关键词；

我们将其中较为常用到的两种关键词提取出来，核心关

键词和长尾关键词。

1. 核心关键词
   核心关键词，指经过关键词分析确定下来的网站“核心“

关键词，通俗地讲指，网站产品和服务的目标客户可能用来搜

索的关键词。

核心关键词具有这些特征：

a. 核心关键词一般作为网站首页的标题。

b. 核心关键词一般是 2~4 个字构成的一个词或词组，名

词居多。

c. 核心关键词在搜索引擎上每日都有一定数目的稳定搜

索量。

d. 搜索核心关键词的用户往往对网站的产品和服务有需

求，或者对网站的内容感兴趣。

e. 网站的主要内容围绕核心关键词展开。

例如：杯子

2. 长尾关键词
   指网站上非目标关键词但也能带来搜索流量的关键词。
   长尾关键词的特征是比较长，往往是 2~3 个词组成，甚至
   是短语，存在于内容页面，除了内容页的标题，还存在于内容
   中。 搜索量非常少，并且不稳定。
   例如：杯子盖，大杯子，有花纹的杯子，什么杯子好看等。

## 优化页面结构

+ 尽量简单、开门见山，提倡扁平化结构
+ 一般而言，建立的网站结构层次越少，越容易被“蜘蛛”抓取，也就容易被收录。一般中小型网站目录结构超过三级，“蜘蛛”便不愿意往下爬了。并且根据相关数据调查：如果访客经过跳转 3 次还没找到需要的信息，很可能离开。因此，三层目录结构也是体验的需要。

### 控制首页链接数量

+ 网站首页是权重最高的地方，如果首页链接太少，没有“桥”，“蜘蛛”不能继续往下爬到内页，直接影响网站收录数量。但是首页链接也不能太多，一旦太多，没有实质性的链接，很容易影响用户体验，也会降低网站首页的权重，收录效果也不好。

### 扁平化的目录层次

+ 尽量让“蜘蛛”只要跳转 3 次，就能到达网站内的任何一个内页。

### 导航优化

+ 导航应该尽量采用文字方式，也可以搭配图片导航，但是图片代码一定要进行优化，\<img>标签必须添加“alt”和“title”属性，告诉搜索引擎导航的定位，做到即使图片未能正常显示时，用户也能看到提示文字。
+ 其次，在每一个网页上应该加上面包屑导航。好处：从用户体验方面来说，可以让用户了解当前所处的位置以及当前页面在整个网站中的位置，帮助用户很快了解网站组织形式，从而形成更好的位置感，同时提供了返回各个页面的接口，方便用户操作；对“蜘蛛”而言，能够清楚的了解网站结构，同时还增加了大量的内部链接，方便抓取，降低跳出率。
+ 蜘蛛是顺着连接爬取的

**注意**

+ 分页导航写法，推荐写法：“首页 1 2 3 4 5 6 7 8 9 下拉框”，这样“蜘蛛”能够根据相应页码直接跳转，下拉框直接选择页面跳转。而下面的写法是不推荐的，“首页 下一页 尾页”，特别是当分页数量特别多时，“蜘蛛”需要经过很多次往下爬，才能抓取，会很累、会容易放弃。

### 网站的结构布局

+ 页面头部：logo 及主导航，以及用户的信息。
+ 页面主体：左边正文，包括面包屑导航及正文；右边放热门文章及相关文章，好处：留住访客，让访客多停留，对“蜘蛛”而言，这些文章属于相关链接，增强了页面相关性，也能增强页面的权重。

  > 掘金，知乎

+ 页面底部：版权信息和友情链接。

### 重要内容 HTML 代码放在最前

+ 搜索引擎抓取 HTML 内容是从上到下，利用这一特点，可以让主要代码优先读取，广告等不重要代码放在下边。例如，在左栏和右栏的代码不变的情况下，只需改一下样式，利用 float:left; 和 float:right; 就可以随意让两栏在展现上位置互换，这样就可以保证重要代码在最前，让爬虫最先抓取。同样也适用于多栏的情况。

### 首屏优化

+ 一个页面最好不要超过 100k，太大，页面加载速度慢。当速度很慢时，用户体验不好，留不住访客，并且一旦超时，“蜘蛛”也会离开。

### Url 优化

- 301 跳转：当用户或搜索引擎向服务器发出浏览请求时，服务器返回的状态码中的一种。表示本网站永久性的转移到另一个地址。同时 302 是暂时重定向
- 有很多朋友在输入网站有这样一个习惯。输入百度地址的时候会直接输入 "baidu.com" 会直接跳到 "https://www.baidu.com/" 这就是重定向技术。 网站加上 www 和不加 www 对搜索引擎来说是两个站点，这样用户访问的时候会导致流量分散，导致页面的权重降低。
- 我咨询过专业的 SEO 公司从业者，他们建议在 URL 中用 id 代替 slug。
  原因嘛，就是说 URL 中包含中文，对百度不友好，对 Google 也没什么意义。
  然后我去看了 SEO 做的很好的网站，如各大电商、36kr 等，都是用 id 代替 slug。
  所以就不折腾 slug 了。
- <https://zhuanlan.zhihu.com/p/25713077>

## 网页代码优化

### 语义化 HTML 代码

+ 尽量让代码语义化，在适当的位置使用适当的标签，用正确的标签做正确的事。让阅读源码者和“蜘蛛”都一目了然。比如：h1-h6 是用于标题类的，\<nav>标签是用来设置页面主导航，列表形式的代码使用 ul 或 ol，重要的文字使用 strong 等。
+ 正文标题要用\<h1>标签：h1 标签自带权重“蜘蛛” 认为它最重要，一个页面有且最多只能有一个 H1 标签，放在该页面最重要的标题上面，如首页的 logo 上可以加 H1 标签。副标题用\<h2>标签, 而其它地方不应该随便乱用 h 标题标签。
+ \<strong>、\<em>标签 ：需要强调时使用。\<strong>标签在搜索引擎中能够得到高度的重视，它能突出关键词，表现重要的内容，\<em>标签强调效果仅次于\<strong>标签；\<b>、\<i>标签：只是用于显示效果时使用，在 SEO 中不会起任何效果。

### \<a>标签

+ 页内链接，要加 “title” 属性加以说明，让访客和 “蜘蛛” 知道。而外部链接，链接到其他网站的，则需要加上 rel="nofollow" 属性, 告诉 “蜘蛛” 不要爬，因为一旦“蜘蛛”爬了外部链接之后，就不会再回来了。

  ```html
  <a href="https://www.360.cn" title="360安全中心" class="logo"></a>
  ```

  ```html
  <a rel="nofollow" href="url">
  ```

### **锚文本链接**

- 在文章正文内容里，把关键词做一个链接，指向特定网页地址，这种形式的链接就叫作锚文本链接。锚文本链接不仅仅点击率会非常高，而且对于网站排名来说效果也是最好的，是最佳的内链形式之一。

锚文本链接的主要作用有：

1、有助于搜索引擎更快的爬行网站　　 对于搜索引擎来说，锚文本的作用之一就是有引导作用。合理的分布站内锚文本，会使搜索引擎蜘蛛更快速的爬行网站目录，这和我们经常说的面包屑导航有异曲同工之妙，这也是对搜索引擎友好的一种表现。

2、提高排名　 合理的站内锚文本指向会使引擎更加准确的认识文章的内容所要描述信息，从而使长尾关键词排名提升，网站权重增加。外部链接的锚文本也会给网站很高的关键权重。

3、增加用户体验　 当用户浏览某一个页面的时候，可能文章的内容对用户而言不是非常的有用，这个时候锚文本就起到了一种引导性的作用，通过锚文本，用户往往会更快更准确的找到自己需要的资料。那么对于没有做网站锚文本的网站而言，当用户没有找到自己需要的东西的时候，他们常见的动作就是关闭页面，这也从反面验证了站内锚文本对于用户体验的作用。

锚文本链接建议采取手动添加的方式，避免自动添加，单个页面的锚文本链接不宜过多，锚文本内容应该和目标页面内容相一致。

### 图片

+ \<img>应使用 "alt" 属性加以说明

  ```html
  <img src="cat.jpg" width="300" height="200" alt="猫"  />
  ```

+ 当网络速度很慢，或者图片地址失效的时候，就可以体现出 alt 属性的作用，他可以让用户在图片没有显示的时候知道这个图片的作用。同时为图片设置高度和宽度，可提高页面的加载速度。

### 字符实体

+ 文本缩进不要使用特殊符号 &nbsp; 应当使用 CSS 进行设置。版权符号不要使用特殊符号 &copy; 可以直接使用输入法打出版权符号©。

### JS

+ 重要内容不要用 JS 输出，因为“蜘蛛”不会读取 JS 里的内容，所以重要内容必须放在 HTML 里。

### Iframe 框架

+ 尽量少使用 iframe 框架,因为“蜘蛛”一般不会读取其中的内容。

### display:none

+ 尽量少使用 iframe 框架,因为“蜘蛛”一般不会读取其中的内容。

### **404 页面**

+ 404 网页是用户尝试访问网站不存在的网页（由于用户点击了损坏的链接、网页已被删除或用户输入了错误的网址）时看到的页面。之所以称为 404 网页，是因为针对丢失网页的请求，网络服务器会返回 404 HTTP 状态代码，表明该网页未找到。

  用户偶尔会因点击失效的链接或输入错误的 URL 而访问一些在网站域名下但并不存在的页面。使用自定义 404 网页能有效地帮助用户回到网站中有效页面，大大提高用户体验。404 网页最好能提供回到网站主页的链接以及到网站中热门内容页面的链接。

  通常用户最好创建一个自定义的 404 网页，以便获得这部分用户流量。一个好的自定义 404 网页可以帮助用户找到所需信息、提供其他实用内容及吸引用户进一步浏览用户的网站。

  不过，很多网站设计的 404 页面都很简单，不少网站为了不损失流量，在 404 页面里面自动重定向到首页的方式，这并不是一个改善用户体验的设计方法。

## 处理页面抓取

### Robot 优化

- meta robot(Robots Meta Directives)

  ```html
  <meta name="robots" contect="all|none|index|noindex|follow|nofollow">
  ```

- 其中的属性说明如下：
  - 设定为 all：文件将被检索，且页面上的链接可以被查询；
  - 设定为 none：文件将不被检索，且页面上的链接不可以被查询；
  - 设定为 index：文件将被检索；
  - 设定为 follow：页面上的链接可以被查询；
  - 设定为 noindex：文件将不被检索，但页面上的链接可以被查询；
  - 设定为 nofollow：文件将不被检索，页面上的链接可以被查询。

### robot.txt

- robots.txt 是一个纯文本文件，在这个文件中网站管理者可以声明该网站中不想被 robots 访问的部分，或者指定搜索引擎可以收录的内容，这是一个针对搜索文件设置的内容。
- 当爬虫爬取一个站点的内容的时候，它会首先检查该站点目录下面是否存在 robots.txt 文件，如果存在，爬虫就会根据文件来内容来爬取，如果不存在，爬虫就会沿着链接抓取。
- robots.txt 必须在根目录下，并且需要全部小写。

  ```txt
  User-agent: *
  Allow: /
  #下列目录除外
  Disallow: /wp-admin/
  Disallow: /wp-includes/
  Disallow: /wp-content/
  
  //以上文本表达的意思是允许所有的搜索机器人访问phpernote.com站点下的除了 wp-admin/，wp-includes/，wp-contents 这几个目录外其他的所有文件。
  
  //具体语法分析：其中#后面文字为注释说明信息；User-agent:后面为搜索机器人的名称，后面如果是*，则泛指所有的搜索机器人；Disallow:后面为不允许访问的文件目录。
  ```

## 性能优化

很多新手站长在搭建网站时，并没有考虑到主机空间对

网站优化的重要性。之所以在这里首先强调网站的访问速度，

是因为它不仅仅影响到网站关键词排名的优化，还会影响网

站的用户体验度和跳出率。因为在这个快节奏的时代，没有人

愿意花时间去等待，即使你费心地优化出一些效果，而这些效

果却不能被很好地转化，那么也将是在做无用功。所以我们在

搭建网站时，一定要选择比较快速的、稳定的主机。

# 单页应用 SEO

<https://juejin.im/post/5c7ce4b5f265da2dbc59ab2a>

<https://www.jianshu.com/p/fcb98533bc18>

<https://github.com/phodal/articles/issues/20>

# 移动优先

<https://lusongsong.com/blog/post/11155.html>

<https://lusongsong.com/blog/post/11743.html>

# 搜索算法

<http://wiki.jikexueyuan.com/project/seo/47.html>

信风算法：<https://lusongsong.com/blog/post/11759.html>
